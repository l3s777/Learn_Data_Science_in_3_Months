{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello world!\n",
    "from my fav videos on week 1 and learning about Python for Machine Learning, we have Deep Dream.\n",
    "\n",
    "We'll go over Siraj's code and try to understand what is happening for such fun thing!\n",
    "\n",
    "Find the info here: https://github.com/llSourcell/deep_dream_challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install what is missing with pip\n",
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# import urllib.request -> for python 3\n",
    "from urllib2 import urlopen\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# main function\n",
    "\n",
    "def main():\n",
    "    #Step 1 - download google's pre-trained neural network\n",
    "    url = 'https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip'\n",
    "    data_dir = '../data/'\n",
    "    model_name = os.path.split(url)[-1]\n",
    "    local_zip_file = os.path.join(data_dir, model_name)\n",
    "\n",
    "    if not os.path.exists(local_zip_file):\n",
    "        # Download\n",
    "        model_url = urllib.request.urlopen(url)\n",
    "        with open(local_zip_file, 'wb') as output:\n",
    "            output.write(model_url.read())\n",
    "        # Extract\n",
    "        with zipfile.ZipFile(local_zip_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(data_dir)\n",
    "  \n",
    "    # start with a gray image with a little noise\n",
    "    img_noise = np.random.uniform(size=(224,224,3)) + 100.0 #little noise\n",
    "  \n",
    "    model_fn = 'tensorflow_inception_graph.pb'\n",
    "    \n",
    "    #Step 2 - Creating Tensorflow session and loading the model\n",
    "    graph = tf.Graph()\n",
    "    sess = tf.InteractiveSession(graph=graph)\n",
    "    with tf.gfile.FastGFile(os.path.join(data_dir, model_fn), 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    t_input = tf.placeholder(np.float32, name='input') # define the input tensor\n",
    "    imagenet_mean = 117.0\n",
    "    t_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0)\n",
    "    tf.import_graph_def(graph_def, {'input':t_preprocessed})\n",
    "    \n",
    "    layers = [op.name for op in graph.get_operations() if op.type=='Conv2D' and 'import/' in op.name]\n",
    "    feature_nums = [int(graph.get_tensor_by_name(name+':0').get_shape()[-1]) for name in layers]\n",
    "    \n",
    "    # printing info\n",
    "    print('Number of layers', len(layers))\n",
    "    print('Total number of feature channels:', sum(feature_nums))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Helper functions for TF Graph visualization\n",
    "    #pylint: disable=unused-variable\n",
    "    def strip_consts(graph_def, max_const_size=32):\n",
    "        \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "        strip_def = tf.GraphDef()\n",
    "        for n0 in graph_def.node:\n",
    "            n = strip_def.node.add() #pylint: disable=maybe-no-member\n",
    "            n.MergeFrom(n0)\n",
    "            if n.op == 'Const':\n",
    "                tensor = n.attr['value'].tensor\n",
    "                size = len(tensor.tensor_content)\n",
    "                if size > max_const_size:\n",
    "                    tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "        return strip_def\n",
    "\n",
    "    def rename_nodes(graph_def, rename_func):\n",
    "        res_def = tf.GraphDef()\n",
    "        for n0 in graph_def.node:\n",
    "            n = res_def.node.add() #pylint: disable=maybe-no-member\n",
    "            n.MergeFrom(n0)\n",
    "            n.name = rename_func(n.name)\n",
    "            for i, s in enumerate(n.input):\n",
    "                n.input[i] = rename_func(s) if s[0]!='^' else '^'+rename_func(s[1:])\n",
    "        return res_def\n",
    "\n",
    "    def showarray(a):\n",
    "        a = np.uint8(np.clip(a, 0, 1)*255)\n",
    "        plt.imshow(a)\n",
    "        plt.show()\n",
    "\n",
    "    def visstd(a, s=0.1):\n",
    "        '''Normalize the image range for visualization'''\n",
    "        return (a-a.mean())/max(a.std(), 1e-4)*s + 0.5\n",
    "\n",
    "    def T(layer):\n",
    "        '''Helper for getting layer output tensor'''\n",
    "        return graph.get_tensor_by_name(\"import/%s:0\"%layer)\n",
    "\n",
    "    def render_naive(t_obj, img0=img_noise, iter_n=20, step=1.0):\n",
    "        t_score = tf.reduce_mean(t_obj) # defining the optimization objective\n",
    "        t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!\n",
    "\n",
    "        img = img0.copy()\n",
    "        for _ in range(iter_n):\n",
    "            g, _ = sess.run([t_grad, t_score], {t_input:img})\n",
    "            # normalizing the gradient, so the same step size should work \n",
    "            g /= g.std()+1e-8         # for different layers and networks\n",
    "            img += g*step\n",
    "        showarray(visstd(img))\n",
    "\n",
    "    def tffunc(*argtypes):\n",
    "        '''Helper that transforms TF-graph generating function into a regular one.\n",
    "            See \"resize\" function below.\n",
    "        '''\n",
    "        placeholders = list(map(tf.placeholder, argtypes))\n",
    "        def wrap(f):\n",
    "            out = f(*placeholders)\n",
    "            def wrapper(*args, **kw):\n",
    "                return out.eval(dict(zip(placeholders, args)), session=kw.get('session'))\n",
    "            return wrapper\n",
    "        return wrap\n",
    "\n",
    "    def resize(img, size):\n",
    "        img = tf.expand_dims(img, 0)\n",
    "        return tf.image.resize_bilinear(img, size)[0,:,:,:]\n",
    "    resize = tffunc(np.float32, np.int32)(resize)\n",
    "\n",
    "    def calc_grad_tiled(img, t_grad, tile_size=512):\n",
    "        '''Compute the value of tensor t_grad over the image in a tiled way.\n",
    "        Random shifts are applied to the image to blur tile boundaries over \n",
    "        multiple iterations.'''\n",
    "        sz = tile_size\n",
    "        h, w = img.shape[:2]\n",
    "        sx, sy = np.random.randint(sz, size=2)\n",
    "        img_shift = np.roll(np.roll(img, sx, 1), sy, 0)\n",
    "        grad = np.zeros_like(img)\n",
    "        for y in range(0, max(h-sz//2, sz),sz):\n",
    "            for x in range(0, max(w-sz//2, sz),sz):\n",
    "                sub = img_shift[y:y+sz,x:x+sz]\n",
    "                g = sess.run(t_grad, {t_input:sub})\n",
    "                grad[y:y+sz,x:x+sz] = g\n",
    "        return np.roll(np.roll(grad, -sx, 1), -sy, 0)\n",
    "    \n",
    "    #CHALLENGE - Write a function that outputs a deep dream video\n",
    "    #def render_deepdreamvideo():\n",
    "        \n",
    "        \n",
    "    def render_deepdream(t_obj, img0=img_noise,\n",
    "                         iter_n=10, step=1.5, octave_n=4, octave_scale=1.4):\n",
    "        t_score = tf.reduce_mean(t_obj) # defining the optimization objective\n",
    "        t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!\n",
    "\n",
    "        # split the image into a number of octaves\n",
    "        img = img0\n",
    "        octaves = []\n",
    "        for _ in range(octave_n-1):\n",
    "            hw = img.shape[:2]\n",
    "            lo = resize(img, np.int32(np.float32(hw)/octave_scale))\n",
    "            hi = img-resize(lo, hw)\n",
    "            img = lo\n",
    "            octaves.append(hi)\n",
    "\n",
    "        # generate details octave by octave\n",
    "        for octave in range(octave_n):\n",
    "            if octave>0:\n",
    "                hi = octaves[-octave]\n",
    "                img = resize(img, hi.shape[:2])+hi\n",
    "            for _ in range(iter_n):\n",
    "                g = calc_grad_tiled(img, t_grad)\n",
    "                img += g*(step / (np.abs(g).mean()+1e-7))\n",
    "\n",
    "            #this will usually be like 3 or 4 octaves\n",
    "            #Step 5 output deep dream image via matplotlib\n",
    "            showarray(img/255.0)\n",
    "\n",
    "\n",
    "\n",
    "    #Step 3 - Pick a layer to enhance our image\n",
    "    layer = 'mixed4d_3x3_bottleneck_pre_relu'\n",
    "    channel = 139 # picking some feature channel to visualize\n",
    "\n",
    "    #open image\n",
    "    img0 = PIL.Image.open('pilatus800.jpg')\n",
    "    img0 = np.float32(img0)\n",
    "\n",
    "    #Step 4 - Apply gradient ascent to that layer\n",
    "    render_deepdream(tf.square(T('mixed4c')), img0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your dependencies installed via pip, run the demo script in terminal via\n",
    "\n",
    "python deep_dream.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
